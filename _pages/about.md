---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Hello, I am Ao Liu (ÂàòÂÇ≤Ôºå „É™„É•„Ç¶„ÄÄ„Ç¢„Ç™), a final-year Ph.D. student at Tokyo Institute of Technology.

My research interest includes natural language generation, semi-supervised learning and pretrained language models. 


# üî• News
- *2022.11*: &nbsp;üéâüéâ Finished my internship at IBM Research Tokyo. 
- *2022.10*: &nbsp;üéâüéâ A long paper accepted at EMNLP 2022.

# üìñ Educations
- *2020.09 - 2023.09*, doctoral student in the Department of Computer Science of Tokyo Institute of Technology, advised by Prof. Naoaki Okazaki.
- *2017.09 - 2020.06*, master student in the School of Computer Science and Engineering of UESTC, advised by Prof. Zenglin Xu.
- *2013.09 - 2017.06*, undergraduate student in the School of Information and Communication Engineering of University of Electronic Science and Technology of China (UESTC), advised by Prof. Zenglin Xu.
- *2015.09 - 2016.08*, exchange student in the JUSST program of the University of Electro-Communications, advised by Prof. Hisashi Koga.

# üíº Internships
- *2022.08 - 2022.11*, IBM Research Tokyo, advised by Dr. Yang Zhao.
- *2021.11 - 2022.06*, Microsoft Research Asia, advised by Haoyu Dong.

# üìù Preprints
- Improving Logical-level Natural Language Generation with Topic-conditioned Data Augmentation and Logical Form Generation. [\[paper\]](https://arxiv.org/abs/2112.06240). **Ao Liu**, Congjian Luo, Naoaki Okazaki.
-  Towards Effective Multi-Task Interaction for Entity-Relation Extraction: A Unified Framework with Selection Recurrent Network. [\[paper\]](https://arxiv.org/abs/2202.07281). An Wang, **Ao Liu**, Hieu Hanh Le and Haruo Yokota.

# üìù Publications 
- PLOG: Table-to-Logic Pretraining for Logical Table-to-Text Generation. [\[paper\]](https://arxiv.org/abs/2205.12697); [\[code\]](https://github.com/microsoft/PLOG). **Ao Liu**, Haoyu Dong, Naoaki Okazaki, Shi Han, Dongmei Zhang. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (**EMNLP 2022**).
- Exploiting Unlabeled Data for Target-Oriented Opinion Words Extraction. [\[paper\]](https://arxiv.org/abs/2208.08280); [\[code\]](https://github.com/TOWESSL/TOWESSL). Yidong Wang, Hao Wu, **Ao Liu**, Wenxin Hou, Zhen Wu, Jindong Wang, Takahiro Shinozaki, Manabu Okumura, Yue Zhang. International Conference on Computational Linguistics 2022 (**COLING 2022**).
- A Unified Weight Initialization Paradigm for Tensorial Convolutional Neural Networks. [\[paper\]](https://arxiv.org/abs/2205.15307). Yu Pan, Zeyong Su, **Ao Liu**, Wang J Q, Nannan Li, Zenglin Xu. Thirty-ninth International Conference on Machine Learning (**ICML 2022**).
- Table Pretraining: A Survey on Model Architectures, Pretraining Objectives, and Downstream Tasks. [\[paper\]](https://arxiv.org/abs/2201.09745). Haoyu Dong, Zhoujun Cheng, Xinyi He, Mengyu Zhou, Anda Zhou, Fan Zhou, **Ao Liu**, Shi Han and Dongmei Zhang. The 31st International Joint Conference on Artificial Intelligence. (**IJCAI-ECAI 2022**, Survey Track).
- Semi-Supervised Formality Style Transfer with Consistency Training [\[paper\]](https://arxiv.org/abs/2203.13620); [\[code\]](https://github.com/aolius/semi-fst). **Ao Liu**, An Wang, Naoaki Okazaki. Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (**ACL 2022**).
- Multi-Level Multimodal Transformer Network for Multi-Modal Recipe Comprehension. [\[paper\]](https://dl.acm.org/doi/abs/10.1145/3397271.3401247). **Ao Liu**, Shuai Yuan, Chenbin Zhang, Congjian Luo, Yaqing Liao, Zenglin Xu. Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (short) (**SIGIR 2020**).
- Improving Contextual Language Models for Response Retrieval in Multi-Turn Conversation. [\[paper\]](https://dl.acm.org/doi/abs/10.1145/3397271.3401255). Junyu Lu, Xiancong Ren, Yazhou Ren, **Ao Liu**, Zenglin Xu. Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (short) (**SIGIR 2020**).
- Read, Attend, and Exclude: Multi-Choice Reading Comprehension by Mimicking Human Reasoning Process. [\[paper\]](https://dl.acm.org/doi/10.1145/3397271.3401326). Chenbin Zhang, Congjian Luo, Junyu Lu, **Ao Liu**, Bing Bai, Kun Bai and Zenglin Xu. Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (short) (**SIGIR 2020**).
- Machine Reading Comprehension: Matching and Orders. [\[paper\]](https://dl.acm.org/doi/10.1145/3357384.3358139); [\[code\]](https://github.com/Aolius/OrdMatch). **Ao Liu**, Lizhen Qu, Junyu Lu, Chenbin Zhang, Zenglin Xu. Proceedings of the 28th ACM International Conference on Information and Knowledge Management (short) (**CIKM 2019**).



# üéñ Honors and Awards

- Stars of Tomorrow, Microsoft Research Asia, 2022.
- Tokyo Tech Advanced Human Resource Development Fellowship for Doctoral Students, Tokyo Institute of Technology, 2021-2023 (Scholarship 1,800,000 JPY/year, Research Funds 300,000 JPY/year)
- Tsubame Scholarship, Tokyo Institue of Technology, 2020.
- SIGIR Student Travel Grants: SIGIR2020, CIKM2019.

# üí¨ Talks
- *2022.08*, *Table-to-Logic Pretraining for Logical Table-to-Text Generation.* Invited talk at Knowledge and Information Research TeamÔºåNational Institute of Advanced Industrial Science and Technology (AIST).

# üìÑ Academic Services
- Reviewer for Conferences: ICML 2022, NeurIPS 2022, EMNLP 2022.
